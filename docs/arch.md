# RAGFlow 架构设计文档

## 1. 系统概述

RAGFlow 是一个基于 Retrieval-Augmented Generation (RAG) 技术的知识库检索增强生成系统，支持多种文档格式的处理、向量化和语义检索。系统采用模块化设计，支持多租户、多知识库管理，并提供丰富的 AI 能力，包括文档处理、向量检索、大语言模型接入等功能。

### 1.1 系统目标

- 提供高效的文档处理和向量化能力
- 实现多种文档格式的语义理解
- 支持多租户、多知识库的管理
- 提供灵活的 API 接口和可视化界面
- 支持复杂的 RAG 增强功能（如 RAPTOR、GraphRAG 等）

### 1.2 关键功能

- 文档上传与处理
- 文档向量化与检索
- 知识库管理
- 对话与查询
- 智能体集成
- 图谱生成与分析

## 2. 架构设计

### 2.1 总体架构

RAGFlow 采用前后端分离的架构设计，后端使用 Python Flask 框架，前端使用现代 Web 技术栈。系统分为以下几个主要部分：

1. **Web 前端**: 提供用户交互界面
2. **API 服务**: 提供 RESTful API 接口
3. **任务执行系统**: 处理异步任务（文档处理、向量化等）
4. **存储系统**: 管理文件、向量和元数据
5. **模型服务**: 集成各种 AI 模型（LLM、嵌入模型等）

*系统架构图可通过以下方式获取：*

参见 [架构图描述文件](references/architecture.md)，这是一个使用Mermaid语法描述的架构图。您可以使用以下工具将其渲染为图像：
- VS Code 的 Mermaid 预览插件
- [Mermaid Live Editor](https://mermaid-js.github.io/mermaid-live-editor/)
- GitHub 原生支持 Mermaid 图表渲染

### 2.2 核心组件

#### 2.2.1 API 服务

API 服务基于 Flask 构建，提供了一系列 RESTful 接口，包括：

- 用户认证与授权
- 文档上传与管理
- 知识库操作
- 对话与查询
- 系统配置

核心 API 模块在 `/api/apps/` 目录下，包括：

- `user_app.py`: 用户管理
- `kb_app.py`: 知识库管理
- `document_app.py`: 文档管理
- `conversation_app.py`: 对话管理
- `file_app.py`: 文件管理
- 其他应用模块

#### 2.2.2 任务执行系统

任务执行系统采用 Redis 作为消息队列，实现异步任务处理：

- `task_executor.py`: 任务执行器，处理文档分块、向量化等任务
- `redis_conn.py`: Redis 连接与队列管理
- `task_service.py`: 任务服务，负责任务创建与状态管理

任务执行流程：
1. 文档上传后创建任务并放入队列
2. 任务执行器从队列获取任务
3. 处理文档（分块、向量化等）
4. 更新任务状态与进度

#### 2.2.3 存储系统

存储系统包括：

- **文件存储**: 支持多种存储后端（本地、MinIO、OSS、S3 等）
- **数据库**: 使用关系型数据库（MySQL/PostgreSQL）存储元数据
- **向量数据库**: 存储文档向量，支持语义检索

相关组件：
- `storage_factory.py`: 存储工厂，统一管理不同的存储后端
- `db_models.py`: 数据库模型定义
- 各种数据库连接器（`es_conn.py`, `infinity_conn.py` 等）

#### 2.2.4 模型服务

模型服务集成了各类 AI 模型：

- `llm/chat_model.py`: 大语言模型接口
- `llm/embedding_model.py`: 嵌入模型接口
- `llm/rerank_model.py`: 重排序模型接口
- 其他模型接口

模型服务支持多种 LLM 提供商，配置在 `conf/llm_factories.json` 中。

#### 2.2.5 智能体系统

智能体系统提供高级 AI 能力：

- `/agent/`: 智能体核心模块
- `/agent/component/`: 智能体组件
- `/agent/canvas.py`: 智能体编排

### 2.3 数据流

系统的主要数据流：

1. **文档处理流**:
   - 用户上传文档
   - 创建任务并放入队列
   - 任务执行器处理文档（分块、向量化）
   - 存储文档向量和元数据

2. **查询检索流**:
   - 用户发送查询
   - 查询向量化
   - 从向量数据库检索相关文档
   - 使用 LLM 生成回答

3. **高级处理流**:
   - RAPTOR 处理（递归抽象）
   - GraphRAG 处理（知识图谱构建与利用）

## 3. 关键模块详解

### 3.1 文档处理模块

文档处理模块负责解析各种格式的文档并进行分块：

- **Parser**: 位于 `/deepdoc/parser/` 目录，支持 PDF、Word、Excel 等格式
- **分块策略**: 根据不同文档类型采用不同的分块策略
- **特殊处理器**: 针对特定类型文档的专用处理器（如 PAPER、LAWS 等）

### 3.2 向量化模块

向量化模块将文档转换为向量表示：

- **嵌入模型**: 支持多种嵌入模型
- **批量处理**: 优化向量化性能
- **混合嵌入**: 支持标题和内容的混合嵌入

### 3.3 任务管理模块

任务管理模块处理异步任务的创建、执行和监控：

- **任务队列**: 使用 Redis Stream 实现
- **任务执行器**: 处理队列中的任务
- **进度追踪**: 实时更新任务进度

### 3.4 知识增强模块

知识增强模块提供高级 RAG 功能：

- **RAPTOR**: 递归抽象处理，生成文档的层次摘要
- **GraphRAG**: 构建知识图谱，支持复杂推理
- **图谱解析与社区分析**: 提供知识图谱的分析能力

## 4. 数据模型

系统的核心数据模型包括：

### 4.1 用户与租户模型

- **User**: 用户信息
- **Tenant**: 租户信息
- **UserTenant**: 用户与租户的关联

### 4.2 知识库模型

- **Knowledgebase**: 知识库基本信息
- **Document**: 文档信息
- **File**: 文件信息
- **File2Document**: 文件与文档的关联

### 4.3 任务模型

- **Task**: 任务信息，包括进度、状态等

### 4.4 对话模型

- **Conversation**: 对话信息
- **Dialog**: 对话中的消息

## 5. 部署架构

系统支持多种部署方式：

### 5.1 单机部署

- 所有组件部署在单台服务器上
- 适用于开发和小规模应用

### 5.2 分布式部署

- API 服务可水平扩展
- 任务执行器可以部署多个实例
- 使用共享存储和数据库
- 支持 Docker 和 Kubernetes 部署

### 5.3 云原生部署

- 支持通过 Helm Chart 部署到 Kubernetes 集群
- 使用云服务提供商的托管服务（数据库、对象存储等）

## 6. 安全性设计

系统的安全设计包括：

- **用户认证**: 基于 Flask-Login 实现
- **数据加密**: 敏感数据加密存储
- **API 权限**: 基于角色的访问控制
- **资源隔离**: 租户级别的资源隔离

## 7. 扩展性设计

系统具有良好的扩展性：

- **模块化设计**: 可以轻松添加新功能模块
- **插件机制**: 支持自定义处理器和模型
- **API 抽象**: 统一的模型接口，易于接入新的模型
- **多后端支持**: 支持多种存储和数据库后端

## 8. 性能优化

系统采用多种性能优化策略：

- **异步处理**: 大型任务异步执行
- **连接池**: 数据库和Redis连接池
- **批量处理**: 向量化和存储的批量操作
- **缓存机制**: 多级缓存策略

## 9. 监控与运维

系统提供完善的监控与运维能力：

- **日志系统**: 结构化日志
- **性能指标**: 任务执行时间、队列长度等
- **异常处理**: 全面的异常捕获和恢复
- **资源监控**: 内存使用、模型加载状态等

## 10. 未来扩展方向

系统可以向以下方向扩展：

- 增强多模态处理能力
- 改进知识图谱构建和推理
- 优化大规模向量检索性能
- 增加更多类型的文档解析器
- 提供更丰富的智能体能力
